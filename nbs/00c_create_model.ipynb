{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TIMM's `create_model` function with all it's **kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might have guessed from the title, in this tutorial we are going to look at the `create_model` function inside `timm` and also look at all the `**kwargs` that can be passed to this function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does `create_model` function do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `timm`, the `create_model` function is responsible for creating the architecture of more than 300 deep learning models! To create a model, simply pass in the `model_name` to `create_model`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import timm \n",
    "# creates resnet-34 architecture\n",
    "model = timm.create_model('resnet34')\n",
    "# creates efficientnet-b0 architecture\n",
    "model = timm.create_model('efficientnet_b0')\n",
    "# creates densenet architecture\n",
    "model = timm.create_model('densenet121')\n",
    "```\n",
    "\n",
    "And so on.. A complete list of available models can be found using `timm.list_models()` function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a pretrained model, simply pass in `pretrained=True` keyword argument to the `timm.create_model` function along with the model name. \n",
    "\n",
    "```python\n",
    "import timm \n",
    "# creates pretrained resnet-34 architecture\n",
    "model = timm.create_model('resnet34', pretrained=True)\n",
    "# creates pretrained efficientnet-b0 architecture\n",
    "model = timm.create_model('efficientnet_b0', pretrained=True)\n",
    "# creates pretrained densenet architecture\n",
    "model = timm.create_model('densenet121', pretrained=True)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a complete list of pretrained models available in `timm`, pass `pretrained=True` to `timm.list_models()` function.\n",
    "```python\n",
    "all_pretrained_models_available = timm.list_models(pretrained=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NOTE: Internally, when we set `pretrained=True`, `timm` get's the model weights from a URL and set's these weights as the pretrained weights. For example, for `resnet34`, `timm` loads the model weights from `https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnet34-43635321.pth`. '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn any model into a feature extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All models support the `features_only=True` argument for `create_model` call to return a network that extracts feature maps from the deepest layer at each stride. It is also possible to specify the indices of the layers to extract the features from using `out_indices=[...]` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm \n",
    "import torch \n",
    "\n",
    "# input batch with batch size of 1 and 3-channel image of size 224x224\n",
    "x = torch.randn(1,3,224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classification model\n",
    "model = timm.create_model('resnet34')\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extractor\n",
    "feature_extractor = timm.create_model('resnet34', features_only=True, out_indices=[2,3,4])\n",
    "out = feature_extractor(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Can you guess the length of `out` if I tell you that out is a list of Tensors?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"Resnet34\" src=\"images/resnet34.png\" width=\"500\" class=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that the `resnet-34` architecture looks like above. If the `7x7` Convolution Layer at the beginning is considered as Layer-0, can you guess the shapes of features coming out from Layer-1, Layer-2, Layer-3 and Layer-4 where each layer is represented by a different color? \n",
    "\n",
    "> NOTE: This might be a great time to open up a Jupyter notebook and do something like this: \n",
    "\n",
    "```python\n",
    "import torch.nn as nn\n",
    "import torch \n",
    "\n",
    "# input batch\n",
    "x = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "pool  = nn.MaxPool2d(3, 2, 1, 1)\n",
    "conv1 = nn.Conv2d(3, 64, 7, stride=2, padding=3)\n",
    "conv2 = nn.Conv2d(64, 64, 3, 1, 1)\n",
    "conv3 = nn.Conv2d(64, 128, 3, 2, 1)\n",
    "\n",
    "# feature map from Layer-0\n",
    "conv1(x).shape\n",
    "# feature map from Layer-1\n",
    "conv2(pool(conv1(x))).shape\n",
    "# and so on.. \n",
    "```\n",
    "\n",
    "> NOTE: If you're looking for resources to read about ResNet architecture, [here](https://github.com/fastai/fastbook/blob/master/14_resnet.ipynb) is an excellent resource in FastBook by [Jeremy Howard](https://twitter.com/jeremyphoward) and [Sylvain Gugger](https://twitter.com/GuggerSylvain)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might have guessed by now, the output shape of the Feature Map from Layer-2, Layer-3 and Layer-4 should be `[1, 128, 28, 28], [[1, 256, 14, 14], [1, 512, 7, 7]` respectively. \n",
    "\n",
    "Let's see if the results match our expectation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 128, 28, 28]),\n",
       " torch.Size([1, 256, 14, 14]),\n",
       " torch.Size([1, 512, 7, 7])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check feature map shapes for Layer-2, Layer-3 and Layer-4\n",
    "[x.shape for x in out]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output shapes of the Feature Maps match our expectation. This way, we can convert any model into a feature extractor in `timm`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
